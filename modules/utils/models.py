"""
LLM æ¨¡å‹ç®¡ç†æ¨¡å—
"""

import streamlit as st
import os
from langchain_aws import ChatBedrockConverse
from typing import Optional, List
import boto3

from dotenv import load_dotenv, find_dotenv

_ = load_dotenv(find_dotenv())


@st.cache_data(show_spinner=False)
def list_bedrock_foundation_models(
    aws_region: str,
    aws_access_key: Optional[str] = None,
    aws_secret_key: Optional[str] = None,
    multimodal_only: bool = True,
) -> List[str]:
    """ä» AWS Bedrock åŠ¨æ€è·å–å¯ç”¨çš„åŸºç¡€æ¨¡å‹

    Args:
        aws_region: åŒºåŸŸï¼Œä¾‹å¦‚ "us-east-1"
        aws_access_key: å¯é€‰ï¼Œè®¿é—®å¯†é’¥
        aws_secret_key: å¯é€‰ï¼Œç§å¯†å¯†é’¥
        multimodal_only: æ˜¯å¦ä»…è¿”å›æ”¯æŒ æ–‡æœ¬+å›¾åƒ -> æ–‡æœ¬ çš„å¤šæ¨¡æ€æ¨¡å‹

    Returns:
        æ¨¡å‹ ID åˆ—è¡¨ï¼ˆæŒ‰å­—æ¯æ’åºï¼‰ã€‚å¤±è´¥æ—¶è¿”å›å®‰å…¨çš„å›é€€åˆ—è¡¨ã€‚
    """
    # å®‰å…¨å›é€€åˆ—è¡¨ï¼ˆAmazon Nova ç³»åˆ—ï¼Œæ”¯æŒ text+image->textï¼‰
    fallback_models = [
        "amazon.nova-pro-v1:0",
        "amazon.nova-lite-v1:0",
        "amazon.nova-micro-v1:0",
    ]

    try:
        # ä¼˜å…ˆä½¿ç”¨æ˜¾å¼å‡­æ®ï¼Œå¦åˆ™èµ°é»˜è®¤å‡­æ®é“¾ï¼ˆç¯å¢ƒå˜é‡/æœ¬åœ°é…ç½®ï¼‰
        if aws_access_key and aws_secret_key:
            session = boto3.Session(
                aws_access_key_id=aws_access_key,
                aws_secret_access_key=aws_secret_key,
                region_name=aws_region,
            )
        else:
            session = boto3.Session(region_name=aws_region)

        client = session.client("bedrock", region_name=aws_region)

        # å¤„ç†åˆ†é¡µ
        summaries = []
        next_token = None
        while True:
            if next_token:
                resp = client.list_foundation_models(nextToken=next_token)
            else:
                resp = client.list_foundation_models()
            summaries.extend(resp.get("modelSummaries", []))
            next_token = resp.get("nextToken")
            if not next_token:
                break

        if not summaries:
            return fallback_models

        def supports_text_image_to_text(summary: dict) -> bool:
            inputs = set(summary.get("inputModalities", []) or [])
            outputs = set(summary.get("outputModalities", []) or [])
            return {"TEXT", "IMAGE"}.issubset(inputs) and "TEXT" in outputs

        filtered = []
        for s in summaries:
            # ä»…é€‰æ‹©æ”¯æŒæŒ‰éœ€æ¨ç†çš„æ¨¡å‹ï¼Œå°½é‡æå‡å¯ç”¨æ€§
            inference_types = set(s.get("inferenceTypesSupported", []) or [])
            if "ON_DEMAND" not in inference_types:
                continue
            if multimodal_only and not supports_text_image_to_text(s):
                continue
            model_id = s.get("modelId")
            if model_id:
                filtered.append(model_id)

        # å»é‡å¹¶æ’åº
        unique_sorted = sorted(list(dict.fromkeys(filtered)))

        # å¦‚æœåŒ…å« nova-proï¼Œåˆ™æå‡ä¸ºé»˜è®¤ï¼ˆæ”¾åˆ°åˆ—è¡¨é¦–ä½ï¼‰
        preferred_model = "amazon.nova-pro-v1:0"
        if preferred_model in unique_sorted:
            unique_sorted = [preferred_model] + [
                m for m in unique_sorted if m != preferred_model
            ]

        return unique_sorted or fallback_models
    except Exception as e:
        # å‡ºé”™æ—¶å›é€€å¹¶æç¤º
        st.warning(f"æœªèƒ½åŠ¨æ€è·å– Bedrock æ¨¡å‹åˆ—è¡¨ï¼Œä½¿ç”¨é»˜è®¤åˆ—è¡¨ã€‚åŸå› : {str(e)}")
        return fallback_models


def get_foundation_models() -> list[str]:
    """å…¼å®¹æ—§æ¥å£ï¼šä»ç¯å¢ƒå˜é‡è¯»å–åŒºåŸŸä¸å‡­æ®ï¼ŒåŠ¨æ€è¿”å›æ¨¡å‹åˆ—è¡¨ã€‚"""
    region = os.getenv("AWS_DEFAULT_REGION", "us-east-1")
    access = os.getenv("AWS_ACCESS_KEY_ID")
    secret = os.getenv("AWS_SECRET_ACCESS_KEY")
    return list_bedrock_foundation_models(
        aws_region=region,
        aws_access_key=access,
        aws_secret_key=secret,
        multimodal_only=True,
    )


@st.cache_resource
def create_chat_model(
    _aws_access_key: str,
    _aws_secret_key: str,
    _aws_region: str,
    _model_id: str,
    _temperature: float,
    _max_tokens: int,
) -> Optional[ChatBedrockConverse]:
    """åˆ›å»ºå¹¶ç¼“å­˜ ChatBedrockConverse æ¨¡å‹"""
    try:
        # è®¾ç½®ç¯å¢ƒå˜é‡
        os.environ["AWS_ACCESS_KEY_ID"] = _aws_access_key
        os.environ["AWS_SECRET_ACCESS_KEY"] = _aws_secret_key
        os.environ["AWS_DEFAULT_REGION"] = _aws_region

        llm = ChatBedrockConverse(
            model=_model_id,
            temperature=_temperature,
            max_tokens=_max_tokens,
            region_name=_aws_region,
        )
        return llm
    except Exception as e:
        st.error(f"æ¨¡å‹åˆ›å»ºå¤±è´¥: {str(e)}")
        return None


def get_model_config_ui():
    """è·å–æ¨¡å‹é…ç½®çš„ UI ç»„ä»¶"""
    st.subheader("ğŸ¤– æ¨¡å‹é…ç½®")

    aws_access_key = st.text_input(
        "AWS Access Key",
        type="password",
        value=os.getenv("AWS_ACCESS_KEY_ID", ""),
        help="è¾“å…¥æ‚¨çš„ AWS Access Key ID",
    )

    aws_secret_key = st.text_input(
        "AWS Secret Key",
        type="password",
        value=os.getenv("AWS_SECRET_ACCESS_KEY", ""),
        help="è¾“å…¥æ‚¨çš„ AWS Secret Access Key",
    )

    aws_region = st.selectbox(
        "AWS Region", ["us-east-1", "us-west-2"], index=0, help="é€‰æ‹© AWS åŒºåŸŸ"
    )

    multimodal_only = st.checkbox(
        "ä»…æ˜¾ç¤ºå¤šæ¨¡æ€æ¨¡å‹ï¼ˆæ–‡æœ¬+å›¾åƒ â†’ æ–‡æœ¬ï¼‰", value=True, help="ç”¨äºå›¾åƒæ€»ç»“ä¸å¯¹è¯"
    )

    # åŠ¨æ€åˆ—å‡ºå¯ç”¨æ¨¡å‹
    model_options = list_bedrock_foundation_models(
        aws_region=aws_region,
        aws_access_key=aws_access_key or None,
        aws_secret_key=aws_secret_key or None,
        multimodal_only=multimodal_only,
    )
    model_id = st.selectbox("Foundation Model", model_options, help="é€‰æ‹©åŸºç¡€æ¨¡å‹")

    col1, col2 = st.columns(2)
    with col1:
        temperature = st.slider(
            "Temperature", 0.0, 1.0, 0.7, 0.1, help="æ§åˆ¶è¾“å‡ºçš„åˆ›é€ æ€§ï¼Œå€¼è¶Šé«˜è¶Šæœ‰åˆ›æ„"
        )
    with col2:
        max_tokens = st.slider(
            "Max Tokens", 500, 5000, 3000, 100, help="é™åˆ¶è¾“å‡ºçš„æœ€å¤§é•¿åº¦"
        )

    return {
        "aws_access_key": aws_access_key,
        "aws_secret_key": aws_secret_key,
        "aws_region": aws_region,
        "model_id": model_id,
        "temperature": temperature,
        "max_tokens": max_tokens,
    }


def create_llm_from_config(config: dict) -> Optional[ChatBedrockConverse]:
    """æ ¹æ®é…ç½®åˆ›å»º LLM æ¨¡å‹"""
    if not config["aws_access_key"] or not config["aws_secret_key"]:
        return None

    return create_chat_model(
        config["aws_access_key"],
        config["aws_secret_key"],
        config["aws_region"],
        config["model_id"],
        config["temperature"],
        config["max_tokens"],
    )
